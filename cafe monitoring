import cv2
import time
import torch
from ultralytics import YOLO
from transformers import AutoProcessor, AutoModelForImageTextToText
from PIL import Image
import numpy as np


# CONFIG

CAMERA_ID = 0
VLM_INTERVAL = 5        # seconds (run VLM every 5 sec)
MODEL_NAME = "Qwen/Qwen2-VL-2B-Instruct"


# LOAD YOLO (REAL-TIME)

print("Loading YOLO...")
yolo = YOLO("yolov8n.pt")  # small & fast (CPU-friendly)


# LOAD VLM (REASONING)

print("Loading Qwen2-VL...")
processor = AutoProcessor.from_pretrained(
    MODEL_NAME,
    use_fast=False
)

vlm = AutoModelForImageTextToText.from_pretrained(
    MODEL_NAME,
    dtype=torch.float32,
    device_map="cpu"
)

print("Models loaded successfully!")


# OPEN WEBCAM

cap = cv2.VideoCapture(CAMERA_ID)
last_vlm_time = 0
vlm_result = "Analyzing..."


# FUNCTION: VLM ANALYSIS

def run_vlm(frame):
    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "image"},
                {
                    "type": "text",
                    "text": "Is this cafe crowded and is staff present?"
                }
            ]
        }
    ]

    prompt = processor.apply_chat_template(
        messages,
        add_generation_prompt=True
    )

    inputs = processor(
        text=prompt,
        images=image,
        return_tensors="pt"
    )

    with torch.no_grad():
        output = vlm.generate(**inputs, max_new_tokens=60)

    return processor.batch_decode(
        output, skip_special_tokens=True
    )[0]


# MAIN LOOP (REAL-TIME)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # -------- YOLO REAL-TIME --------
    results = yolo(frame, conf=0.35, verbose=False)
    person_count = 0

    for r in results:
        for box in r.boxes:
            cls = int(box.cls[0])
            if cls == 0:  # person
                person_count += 1
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

    # -------- VLM EVERY N SECONDS --------
    current_time = time.time()
    if current_time - last_vlm_time > VLM_INTERVAL:
        last_vlm_time = current_time
        vlm_result = run_vlm(frame)

    # -------- DISPLAY INFO --------
    cv2.putText(frame, f"People Count: {person_count}",
                (20, 40), cv2.FONT_HERSHEY_SIMPLEX,
                1, (255, 0, 0), 2)

    cv2.putText(frame, f"VLM: {vlm_result[:60]}",
                (20, 80), cv2.FONT_HERSHEY_SIMPLEX,
                0.6, (0, 0, 255), 2)

    cv2.imshow("Real-Time Cafe Monitoring", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break


# CLEANUP

cap.release()
cv2.destroyAllWindows()
